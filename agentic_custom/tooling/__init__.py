import threading
from dataclasses import dataclass
from typing import Callable, List, Any, Dict

from .tools_context import ToolsContext

class AgentTerminationException(Exception):
    """ Exception raised when the agent is terminated the execution loop."""
    pass

class Argument:
    def __init__(
        self,
        name: str,
        description: str,
        type: str,
        enum: List[str] = None,
        items: str = None,
        required: bool = True,
    ):
        self.name = name
        self.description = description
        self.type = type
        if type == 'array':
            if items is None:
                raise ValueError("items is required for array type")
        self.enum = enum
        self.items = items
        self.required = required

    def print_argument(self):
        required_emoji = "âœ…" if self.required else "âŒ"
        enum_str = ""
        if self.enum:
            enum_values = ', '.join(map(str, self.enum))
            enum_str = f"     â”œâ”€ ğŸ”¢ Enum: [{enum_values}]\n"
        return (
            f"  â””â”€ âš™ï¸  Argument: {self.name}\n"
            f"     â”œâ”€ ğŸ“ Description: {self.description}\n"
            f"     â”œâ”€ ğŸ¯ Type: {self.type}\n"
            f"{enum_str}"
            f"     â””â”€ {required_emoji} Required: {self.required}"
        )

class Tool:
    """
     An helper class used to define a tool. Used for automated schema generation based on the LLM in used.
    """
    def __init__(
        self,
        name: str,
        function: Callable,
        description: str,
        arguments: List[Argument] = [],
    ):
        self.name = name
        self.function = function
        self.description = description
        self.arguments = arguments

    def print_tool(self):
        lines = [
            "=" * 60,
            f"ğŸ”§ Tool: {self.name}",
            f"ğŸ“ Description: {self.description}",
        ]
        if self.arguments:
            lines.append(f"ğŸ“‹ Arguments ({len(self.arguments)}):")
            for argument in self.arguments:
                lines.append(argument.print_argument())
        else:
            lines.append("ğŸ“‹ Arguments: None")
        lines.append("=" * 60)
        return "\n".join(lines)


class ToolCall:
    """
    A class to wrap a tool call from an LLM.
    It has three main responsibilities:
    - It represent the initial tool call generated by the LLM.
    - It takes care of the asynchronous execution of the underlying tool function in a separate thread.
    - It stores the result of the tool execution in the content attribute, whether successful or not, whether it is a termination request or not.
    """
    def __init__(
        self,
        llm,
        raw_tool_call,
    ):
        self.llm = llm
        self.raw_tool_call = raw_tool_call
        self.tool_name = self.llm.get_tool_name(self.raw_tool_call)
        self.tool_args = self.llm.get_tool_args(self.raw_tool_call)
        self.is_tool_invocation_successful = None
        self.content = None
        self.is_termination = None
        self._done = threading.Event()
        self._thread = None

    def is_executed(self):
        return self.is_tool_invocation_successful is not None

    def _run_tool(self, tool_context: ToolsContext):
        try:
            self.content = tool_context.tools_functions[self.tool_name](**self.tool_args)
            self.is_tool_invocation_successful = True
            self.is_termination = False
        except AgentTerminationException as ex:
            self.is_tool_invocation_successful = True
            self.is_termination = True
            self.content = str(ex)
        except Exception as ex:
            self.is_tool_invocation_successful = False
            self.is_termination = False
            self.content = str(ex)
        finally:
            self._done.set()

    def execute(self, tool_context: ToolsContext):
        self._done.clear()
        self._thread = threading.Thread(target=self._run_tool, args=(tool_context,))
        self._thread.start()

    def wait(self, timeout=None):
        if self._thread is not None:
            self._done.wait(timeout=timeout)

    def generate_tool_response_message(self):
        """ Generate a tool result message to be inserted in the messages history. Format depends on the LLM in use."""
        if not self.is_executed():
            raise ValueError("Tool call not executed")

        return self.llm.generate_tool_response_message(self)

    def to_dict(self):
        return {
            "tool_name": self.tool_name,
            "tool_args": self.tool_args,
            "content": self.content,
            "is_tool_invocation_successful": self.is_tool_invocation_successful,
            "is_termination": self.is_termination,
        }